{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Product ID Product Name   Brand         Category   Color Size  \\\n",
      "0            1        Dress  Adidas    Men's Fashion   Black   XL   \n",
      "1            2        Shoes     H&M  Women's Fashion   Black    L   \n",
      "2            3        Dress  Adidas  Women's Fashion  Yellow   XL   \n",
      "3            4        Shoes    Zara    Men's Fashion   White    S   \n",
      "4            5      T-shirt  Adidas    Men's Fashion   Black    M   \n",
      "5            6        Dress  Adidas    Men's Fashion  Yellow    L   \n",
      "6            7        Jeans   Gucci    Men's Fashion   White   XL   \n",
      "7            8      Sweater    Zara    Kids' Fashion    Blue   XL   \n",
      "8            9      Sweater     H&M    Men's Fashion   Green   XL   \n",
      "9           10      T-shirt    Zara    Kids' Fashion   White   XL   \n",
      "10          11      T-shirt  Adidas    Men's Fashion     Red    S   \n",
      "11          12      Sweater   Gucci    Kids' Fashion  Yellow    M   \n",
      "12          13        Jeans    Nike    Kids' Fashion     Red    M   \n",
      "13          14        Dress    Zara  Women's Fashion   White    L   \n",
      "14          15        Shoes    Zara    Men's Fashion  Yellow    M   \n",
      "15          16        Dress  Adidas  Women's Fashion    Blue    S   \n",
      "16          17        Dress   Gucci  Women's Fashion    Blue   XL   \n",
      "17          18        Jeans   Gucci  Women's Fashion     Red   XL   \n",
      "18          19        Shoes   Gucci  Women's Fashion   White    M   \n",
      "19          20        Dress   Gucci    Men's Fashion   Green    L   \n",
      "\n",
      "                                     Content  \n",
      "0      1 Dress Adidas Men's Fashion Black XL  \n",
      "1        2 Shoes H&M Women's Fashion Black L  \n",
      "2   3 Dress Adidas Women's Fashion Yellow XL  \n",
      "3         4 Shoes Zara Men's Fashion White S  \n",
      "4     5 T-shirt Adidas Men's Fashion Black M  \n",
      "5      6 Dress Adidas Men's Fashion Yellow L  \n",
      "6       7 Jeans Gucci Men's Fashion White XL  \n",
      "7       8 Sweater Zara Kids' Fashion Blue XL  \n",
      "8       9 Sweater H&M Men's Fashion Green XL  \n",
      "9     10 T-shirt Zara Kids' Fashion White XL  \n",
      "10     11 T-shirt Adidas Men's Fashion Red S  \n",
      "11   12 Sweater Gucci Kids' Fashion Yellow M  \n",
      "12         13 Jeans Nike Kids' Fashion Red M  \n",
      "13     14 Dress Zara Women's Fashion White L  \n",
      "14      15 Shoes Zara Men's Fashion Yellow M  \n",
      "15    16 Dress Adidas Women's Fashion Blue S  \n",
      "16    17 Dress Gucci Women's Fashion Blue XL  \n",
      "17     18 Jeans Gucci Women's Fashion Red XL  \n",
      "18    19 Shoes Gucci Women's Fashion White M  \n",
      "19      20 Dress Gucci Men's Fashion Green L  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"C:\\Users\\vcsma\\Downloads\\AI PROJECT\\fashion_products.csv\")\n",
    "\n",
    "content_df = data[['Product ID', 'Product Name', 'Brand', 'Category', 'Color', 'Size']].copy()\n",
    "content_df['Content'] = content_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
    "print(content_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "content_df = data[['Product ID', 'Product Name', 'Brand', 'Category', 'Color', 'Size']].copy()\n",
    "content_df['Content'] = content_df.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "content_matrix = tfidf_vectorizer.fit_transform(content_df['Content'])\n",
    "\n",
    "content_similarity = linear_kernel(content_matrix, content_matrix)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(data[['User ID', \n",
    "                                  'Product ID', \n",
    "                                  'Rating']], reader)\n",
    "\n",
    "def get_content_based_recommendations(product_id, top_n):\n",
    "    index = content_df[content_df['Product ID'] == product_id].index[0]\n",
    "    similarity_scores = content_similarity[index]\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:top_n + 1]\n",
    "    recommendations = content_df.loc[similar_indices, 'Product ID'].values\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD()\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "def get_collaborative_filtering_recommendations(user_id, top_n):\n",
    "    testset = trainset.build_anti_testset()\n",
    "    testset = filter(lambda x: x[0] == user_id, testset)\n",
    "    predictions = algo.test(testset)\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    recommendations = [prediction.iid for prediction in predictions[:top_n]]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(predictions, k=10, threshold=4):\n",
    "    top_k_pred = sorted(predictions, key=lambda x: x.est, reverse=True)[:k]\n",
    "    num_relevant = sum((pred.r_ui >= threshold) for pred in top_k_pred)\n",
    "    return num_relevant / min(k, len(predictions))\n",
    "\n",
    "def recall_at_k(predictions, k=10, threshold=4):\n",
    "    top_k_pred = sorted(predictions, key=lambda x: x.est, reverse=True)[:k]\n",
    "    num_relevant = sum((pred.r_ui >= threshold) for pred in top_k_pred)\n",
    "    num_total_relevant = sum((pred.r_ui >= threshold) for pred in predictions)\n",
    "    \n",
    "    if num_total_relevant == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num_relevant / num_total_relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Our Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommender(model, trainset, testset, k=10):\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    precisions, recalls, map_scores = [], [], []\n",
    "    for uid in set([pred.uid for pred in predictions]):\n",
    "        user_predictions = [pred for pred in predictions if pred.uid == uid]\n",
    "        user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        \n",
    "        \n",
    "        top_k_recommended = [pred.iid for pred in user_predictions[:k]]\n",
    "        \n",
    "\n",
    "        true_items = [pred.iid for pred in user_predictions if pred.r_ui >= 4]\n",
    "        \n",
    "\n",
    "        precisions.append(precision_at_k(user_predictions, k))\n",
    "        recalls.append(recall_at_k(user_predictions, k))\n",
    "        \n",
    "        map_score = sum([precision_at_k(user_predictions, i+1) for i, pred in enumerate(user_predictions) if pred.iid in true_items]) / max(1, len(true_items), k)\n",
    "\n",
    "        map_scores.append(map_score)\n",
    "    \n",
    "    \n",
    "    mean_precision = sum(precisions) / len(precisions)\n",
    "    mean_recall = sum(recalls) / len(recalls)\n",
    "    mean_map = sum(map_scores) / len(map_scores)\n",
    "    \n",
    "    return mean_precision, mean_recall, mean_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid Filtering (Combination of Both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_recommendations(user_id, product_id, top_n=15):\n",
    "    content_based_recommendations = get_content_based_recommendations(product_id, top_n)\n",
    "    collaborative_filtering_recommendations = get_collaborative_filtering_recommendations(user_id, top_n)\n",
    "    hybrid_recommendations = list(set(content_based_recommendations + collaborative_filtering_recommendations))\n",
    "    return hybrid_recommendations[:top_n]\n",
    "\n",
    "def get_hybrid_recommendations_for_new_user(user_id, top_n=10):\n",
    "    popular_items = data['Product ID'].value_counts().index[:top_n].tolist()\n",
    "    return popular_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Recommendations for User 10 based on Product 5:\n",
      "1. Product ID: 866\n",
      "2. Product ID: 899\n",
      "3. Product ID: 482\n",
      "4. Product ID: 582\n",
      "5. Product ID: 902\n",
      "6. Product ID: 1896\n",
      "7. Product ID: 1198\n",
      "8. Product ID: 722\n",
      "9. Product ID: 1523\n",
      "10. Product ID: 1718\n",
      "11. Product ID: 921\n",
      "12. Product ID: 1115\n",
      "13. Product ID: 765\n",
      "14. Product ID: 1055\n",
      "Evaluation Metrics:\n",
      "Precision@10: 0.35205761316872425\n",
      "Recall@10: 0.6049382716049383\n",
      "Mean Average Precision: 0.05473251028806585\n"
     ]
    }
   ],
   "source": [
    "user_id = 10\n",
    "product_id = 5\n",
    "top_n = 15\n",
    "\n",
    "if product_id is None:\n",
    "    recommendations = get_hybrid_recommendations_for_new_user(user_id, top_n)\n",
    "    print(f\"Hybrid Recommendations for New User {user_id}:\")\n",
    "else:\n",
    "    recommendations = get_hybrid_recommendations(user_id, product_id, top_n)\n",
    "    print(f\"Hybrid Recommendations for User {user_id} based on Product {product_id}:\")\n",
    "\n",
    "for i, recommendation in enumerate(recommendations):\n",
    "    print(f\"{i + 1}. Product ID: {recommendation}\")\n",
    "\n",
    "\n",
    "trainset, testset = train_test_split(data_surprise, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "precision, recall, map_score = evaluate_recommender(algo, trainset, testset)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision@10: {precision}\")\n",
    "print(f\"Recall@10: {recall}\")\n",
    "print(f\"Mean Average Precision: {map_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
